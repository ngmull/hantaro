tidync(tasmin_name) %>% activate("D0") %>% hyper_array() -> times2
tidync(precip_name) %>% activate("D0") %>% hyper_array() -> times3
# Visual checks for any gaps
plot(times1$time)
stablename <- 'Africa_stable_GL_2'
library(tidync)
library(raster)
library(rgdal)
library(sf)
################## THIS SETS THE RIGHT PARTS RUNNING
unstablename <- 'Africa_unstable_GL_2'
stablename <- 'Africa_stable_GL_2'
tasmax_name <- 'D:/DECIMALS/GLENS/feedback_run2_TREFHTMX_20200101-20991231_1deg.nc'
tasmin_name <- 'D:/DECIMALS/GLENS/feedback_run2_TREFHTMN_202020200101-20991231_1deg.nc'
precip_name <- 'D:/DECIMALS/GLENS/feedback_run2_pr_20200101-20991231_1deg.nc'
# Load in some functions
c2k <- 273.15
tmax1 <- 34 + c2k
tmin1 <- 17 + c2k
fastestize <- function(poly,raster) {
require(fasterize)
y <- disaggregate(raster,10)
p <- st_as_sf(poly)
z <- fasterize(p,y)
x <- raster::aggregate(z,10,fun='sum')/100
return(x)
}
raster_tibble <- function(df) {
rasterFromXYZ(df[,c(2,3,1)])
}
# D2 for G3, D0 for GLENS
tidync(tasmax_name) %>% activate("D0") %>% hyper_array() -> times1; plot(times1$time)
tidync(tasmin_name) %>% activate("D0") %>% hyper_array() -> times2; plot(times2$time)
range(times1)
range(times2)
### CODE FOR 2020 IS BORKEN (THESE START 2020 FIX IN AM)
# FUNCTIONS
#lonrange <- c(144, 247)
#latrange <- c(-46, 47)
SHAPEFILE <- readOGR(layer="GBD-Adjusted",dsn='D:/DECIMALS/Regions')
SSA <- c('Sub-Saharan Africa (East)',
'Sub-Saharan Africa (Central)',
'Sub-Saharan Africa (Southern)',
'Sub-Saharan Africa (West)')
REGIONS <- SHAPEFILE[SHAPEFILE$Region %in% SSA,]
ncmeta::nc_atts(tasmax_name, "time") %>% tidyr::unnest(cols = c(value))
## Visualise statistical and spatial distributions
## (advanced!)
library(maps)
vars <- as.data.frame(state.x77)
StateName <- tolower(state.name)
form <- StateName ~ Population + Income + Illiteracy +
`Life Exp` + Murder + `HS Grad` + Frost + sqrt(Area)
## construct independent maps of each variable
statemap <- map("state", plot = FALSE, fill = TRUE)
colkey <- draw.colorkey(list(col = heat.colors(100), at = 0:100,
labels = list(labels = c("min","max"), at = c(0,100))))
panel.mapplot.each <- function(x, breaks, ...)
panel.mapplot(x = x, breaks = quantile(x), ...)
vmaps <- mapplot(form, vars, map = statemap, colramp = heat.colors,
panel = panel.mapplot.each, colorkey = FALSE,
legend = list(right = list(fun = colkey)), xlab = NULL)
## construct independent densityplots of each variable
vdens <- densityplot(form[-2], vars, outer = TRUE, cut = 0,
scales = list(relation = "free"), ylim = c(0, NA),
cex = 0.5, ref = TRUE) +
layer(panel.axis("top", half = FALSE, text.cex = 0.7))
## combine panels from both plots
combo <- c(vmaps, vdens)
## rearrange in pairs
n <- length(vars)
npairs <- rep(1:n, each = 2) + c(0, n)
update(combo[npairs], scales = list(draw = FALSE),
layout = c(4, 4), between = list(x = c(0, 0.5), y = 0.5))
# }
## Combine different types of plots.
c(wireframe(volcano), contourplot(volcano))
## Merging levelplot with xyplot
levObj <- levelplot(prop.table(WorldPhones, 1) * 100)
xyObj <- xyplot(Phones ~ Year, data.frame(Phones = rowSums(WorldPhones),
Year = row.names(WorldPhones)), type="b", ylim = c(0, 150000))
## NOTE: prepanel.levelplot (from first object) is used for entire plot.
cObj <- c(levObj, xyObj, layout = 1:2)
update(cObj, scales = list(y = list(rot = 0)),
ylab = c("proportional distribution", "number of phones"))
## Combine two xyplots.
sepals <- xyplot(Sepal.Length ~ Sepal.Width, iris, groups = Species,
xlab = "Width", ylab = "Height")
petals <- xyplot(Petal.Length ~ Petal.Width, iris, groups = Species)
c(Sepals = sepals, Petals = petals)
## Force same scales (re-calculate panel limits from merged data):
c(Sepals = sepals, Petals = petals, x.same = TRUE, y.same = TRUE)
## Or - create xyplots from a list of formulas
xyplot.list(list(Sepals = Sepal.Length ~ Sepal.Width,
Petals = Petal.Length ~ Petal.Width),
data = iris, groups = Species, x.same = TRUE,
xlab = "Width", ylab = "Height")
## Create histograms from a list of objects, and merge them.
xyplot.list(iris, FUN = histogram)
## Create cumulative distribution plots from a list of objects
xyplot.list(iris[1:4], FUN = qqmath, groups = iris$Species,
auto.key = TRUE)
## Display a table as both frequencies and proportions:
data(postdoc)
## remove last row (containing totals)
postdoc <- postdoc[1:(nrow(postdoc)-1),]
pdprops <- barchart(prop.table(postdoc, margin = 1),
auto.key = list(adj = 1))
pdmargin <- barchart(margin.table(postdoc, 1))
pdboth <- c(pdprops, pdmargin)
update(pdboth, xlab = c("Proportion", "Freq"))
## Conditioned 'quakes' plot combined with histogram.
qua <- xyplot(lat ~ long | equal.count(depth, 3), quakes,
aspect = "iso", pch = ".", cex = 2, xlab = NULL, ylab = NULL)
qua <- c(qua, depth = histogram(quakes$depth), layout = c(4, 1))
## suppress scales on the first 3 panels
update(qua, scales = list(at = list(NULL, NULL, NULL, NA),
y = list(draw = FALSE)))
## Demonstrate merging of legends and par.settings.
## Note that par.settings can conflict, thus need col.line=...
mypoints <-
xyplot(1:10 ~ 1:10, groups = factor(rep(1:2, each = 5)),
par.settings = simpleTheme(pch = 16), auto.key = TRUE)
mylines <-
xyplot(1:10 ~ 1:10, groups = factor(rep(1:5, each = 2)),
type = "l", par.settings = simpleTheme(col.line = 1:5),
auto.key = list(lines = TRUE, points = FALSE, columns = 5))
c(mypoints, mylines)
library(lattice)
library(maps)
vars <- as.data.frame(state.x77)
StateName <- tolower(state.name)
form <- StateName ~ Population + Income + Illiteracy +
`Life Exp` + Murder + `HS Grad` + Frost + sqrt(Area)
## construct independent maps of each variable
statemap <- map("state", plot = FALSE, fill = TRUE)
colkey <- draw.colorkey(list(col = heat.colors(100), at = 0:100,
labels = list(labels = c("min","max"), at = c(0,100))))
panel.mapplot.each <- function(x, breaks, ...)
panel.mapplot(x = x, breaks = quantile(x), ...)
vmaps <- mapplot(form, vars, map = statemap, colramp = heat.colors,
panel = panel.mapplot.each, colorkey = FALSE,
legend = list(right = list(fun = colkey)), xlab = NULL)
## construct independent densityplots of each variable
vdens <- densityplot(form[-2], vars, outer = TRUE, cut = 0,
scales = list(relation = "free"), ylim = c(0, NA),
cex = 0.5, ref = TRUE) +
layer(panel.axis("top", half = FALSE, text.cex = 0.7))
## combine panels from both plots
combo <- c(vmaps, vdens)
## rearrange in pairs
n <- length(vars)
npairs <- rep(1:n, each = 2) + c(0, n)
update(combo[npairs], scales = list(draw = FALSE),
layout = c(4, 4), between = list(x = c(0, 0.5), y = 0.5))
library(tidyverse)
edge <- read_csv("C:/Users/cjcar/Downloads/edgelist.csv")
beta <- read_csv("~/Github/Fresnel/BinaryWebsite.csv")
beta
edge
edge %>% filter(virus == 'Betacoronavirus') %>% pull(host) -> srabcv
beta %>% filter(Sp %in% srabcv)
beta %>% filter(Sp %in% srabcv) %>% View()
beta %>% filter(Sp %in% srabcv) %>% select(Sp, `Training data`, `New data`, Ensemble, Trait.1)
edge %>% filter(srabcv %in% beta$Sp)
edge
edge %>% filter(virus == 'Betacoronavirus', host %in% beta$Sp)
beta %>% filter(Sp %in% srabcv) %>% select(Sp, `Training data`, `New data`, Ensemble, Trait.1) -> data1
edge %>% filter(virus == 'Betacoronavirus', host %in% beta$Sp) -> data2
edge %>% filter(virus == 'Betacoronavirus', host %in% beta$Sp) %>% select(-virus) -> data2
edge %>% filter(virus == 'Betacoronavirus', host %in% beta$Sp) %>% select(-virus) %>%
rename(Sp = host) -> data2
left_join(beta, edge)
left_join(data1, data2)
temp <- tidync("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
library(dismo)
library(raster)
library(tidync)
temp <- tidync("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
temp[[,,1]]
temp[[,,,1]]
dim(temp)
temp %>% hyper_filter(time = index < 361)
library(magrittr)
temp %<>% hyper_filter(time = index < 361)
temp %<>% hyper_filter(time = index < 361) %>%
hyper_tibble()
temp %<>% hyper_filter(time = index < 361) %>%
hyper_array()
raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
temp <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
temp <- temp[[1:360]]
prep <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
prep <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
prep1 <- prep[[1:180]]
prep2 <- prep[[181:360]]
bio1 <- cellStats(temp1, 'mean')
?cellStats
library(dismo)
library(raster)
temp <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
temp1 <- temp[[1:180]]
temp2 <- temp[[181:360]]
prep <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
prep1 <- prep[[1:180]]
prep2 <- prep[[181:360]]
########
bio1 <- cellStats(temp1, 'mean')
bio1
bio1 <- calc(temp1, 'mean')
bio1 <- raster::calc(temp1, 'mean')
rwmp1
temp1
bio1 <- raster::calc(temp1, fun = mean)
bio4 <- 100 * raster::calc(temp1, fun = sd)
bio12 <- raster::calc(prep1, fun = sum)
bio15 <- raster::calc(prep1 + 1, fun = cv)
?window
sapply(c(1,2,3,4), window)
sapply(c(1,2,3,4), 1, window)
sapply(c(1,2,3,4), window)
presidents
window(presidents, 1960, c(1969,4)) # values in the 1960's
?biovars
# precip by quarter (3 months)
wet <- t(apply(prep, 1, window))
if(!require(ggregplot)) devtools::install_github("gfalbery/ggregplot") # Installing Greg's package for plotting functions!
library(INLA); library(ggplot2); library(ggregplot)
library(tidyverse)
library(RColorBrewer)
Root <- "C:/Users/cjcar/Desktop" # T
Hosts <- read.csv(paste0(Root, "/HostCaptures.csv"), header = T)
list.files()
Hosts <- read.csv(paste0(Root, "/HostCaptures.csv"), header = T)
head(Hosts)
substr(names(Hosts), 1, 1) <- toupper(substr(names(Hosts), 1, 1)) # Giving the host names capital letters
phen <- c("Grid", "ID", "Easting", "Northing") # Base columns with spatial information we'll need
resp <- "Parasite.count" # Response variable
covar <- c("Month", # Julian month of sampling
"Sex", # Sex
"Smi", # Body condition
"Supp.corrected", # Nutrition supplementation
"Treated") # Treatment
TestHosts <- na.omit(Hosts[, c(phen, resp, covar)]) # Getting rid of NA's, picking adults
# We are using the [] to subset and only extract specific columns
# Turning variables into factors
TestHosts$Month <- as.factor(TestHosts$Month)
TestHosts$Grid <- as.factor(TestHosts$Grid)
TestHosts$Parasite.count <- round(TestHosts$Parasite.count) # Parasite counts should be integers
table(table(TestHosts$ID)) # Enough repeat samples for a mixed model?
# Specify the formula
f0.1 <- as.formula(paste0(resp, " ~ ", # Response first
paste(covar, collapse = " + ") # Collapse the vector of covariates
))
# Run the model
IM0.1  <- inla(Parasite.count ~ Month + Sex + Smi + Supp.corrected + Treated,
family = "nbinomial", # Specify the family. Can be a wide range (see r-inla.org).
data = TestHosts) # Specify the data
# Run the model # (This is the same thing)
IM0.1  <- inla(f0.1,
family = "nbinomial", # Specify the family. Can be a wide range (see r-inla.org).
data = TestHosts) # Specify the data
# Then with an ID random effect ####
f0.2 <- as.formula(paste0(resp, " ~ ",
paste(covar, collapse = " + "),
" +  f(ID, model = 'iid')")) # This is how you include  a typical random effect.
IM0.2  <- inla(f0.2,
family = "nbinomial",
data = TestHosts)
summary(IM0.1)
summary(IM0.2)
if(!require(ggregplot)) devtools::install_github("gfalbery/ggregplot") # Installing Greg's package for plotting functions!
library(INLA); library(ggplot2); library(ggregplot)
library(tidyverse)
library(RColorBrewer)
install.packages('INLA')
library(dismo)
library(raster)
temp <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
temp1 <- temp[[1:180]]
temp2 <- temp[[181:360]]
prep <- raster::brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
prep1 <- prep[[1:180]]
prep2 <- prep[[181:360]]
########
# Past
bio1 <- raster::calc(temp1, fun = mean)
bio4 <- 100 * raster::calc(temp1, fun = sd)
bio12 <- raster::calc(prep1, fun = sum)
bio15 <- raster::calc(prep1 + 1, fun = cv)
?biovars
??dismo::biovars
# Get bioclim vars from climate data
library(raster)
library(dismo)
library(parallel)
library(ncdf4)
setwd("/nfs/ctrisos-data/")
#set years of data
start.year=1981
end.year=1995
#get land grid
#Guessing you don't need this because only have ERA land?
#landgrid<-raster('ClimateModelScript/landMaskQD.tif')
# set the number of cores
detectCores()
mc.cores=8
# Get bioclim vars from climate data
library(raster)
library(dismo)
library(parallel)
library(ncdf4)
#setwd("/nfs/ctrisos-data/")
#set years of data
start.year=1981
end.year=1995
#get land grid
#Guessing you don't need this because only have ERA land?
#landgrid<-raster('ClimateModelScript/landMaskQD.tif')
# set the number of cores
detectCores()
mc.cores=8
# get climate data from netcdf into rasterbricks
tasmax<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
tasmin<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
precip<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
# mask the raster layer to have only land
# tasmin<-mask(tasmin,landgrid,maskvalue=1)
#tasmax<-mask(tasmax,landgrid,maskvalue=1)
#precip<-mask(precip,landgrid,maskvalue=1)
# make a vector with the years in climate data time series
years<-seq(start.year,end.year,1)
nyears=length(years)
# make index for the year
ind=sort(rep(1:nyears,12))
# Calculate bioclim variables for each year using mclapply
bcbricks=mclapply(unique(ind),function(x){
#extract just the climate data for each year from the raster brick
tasmax.year=tasmax[[which(ind==x)]]
tasmin.year=tasmin[[which(ind==x)]]
precip.year=precip[[which(ind==x)]]
# calculate bioclim variables
biovars(precip.year,tasmin.year,tasmax.year)
},mc.cores=mc.cores)
#TWO different options for saving outputs
#2 makes a separate tif file for each bioclim variable
# where each tif is a rasterstack of a single bioclim variable across all years.
# output directory
outDir="C:/Users/cjcar/Desktop/ERA5"
# stack individual bioclim variables across years
lapply(1:nlayers(bcbricks[[1]]),function(x){
bcvar.by.allyears=stack(lapply(bcbricks,function(y){ y[[x]]}))
writeRaster(bcvar.by.allyears,file=paste0(getwd(),outDir,'/',names(bcbricks[[1]])[x],'_',start.year,'_',end.year,'.tif'))
})
?mclapply
# Calculate bioclim variables for each year using mclapply
bcbricks=mclapply(unique(ind),function(x){
#extract just the climate data for each year from the raster brick
tasmax.year=tasmax[[which(ind==x)]]
tasmin.year=tasmin[[which(ind==x)]]
precip.year=precip[[which(ind==x)]]
# calculate bioclim variables
biovars(precip.year,tasmin.year,tasmax.year)
})
#TWO different options for saving outputs
#2 makes a separate tif file for each bioclim variable
# where each tif is a rasterstack of a single bioclim variable across all years.
# output directory
outDir="C:/Users/cjcar/Desktop/ERA5"
# stack individual bioclim variables across years
lapply(1:nlayers(bcbricks[[1]]),function(x){
bcvar.by.allyears=stack(lapply(bcbricks,function(y){ y[[x]]}))
writeRaster(bcvar.by.allyears,file=paste0(getwd(),outDir,'/',names(bcbricks[[1]])[x],'_',start.year,'_',end.year,'.tif'))
})
rentrez::entrez_fetch(db = "nuccore", id = "MW165880.1", rettype="fasta_cds_na")
install.packages('rentrez')
rentrez::entrez_fetch(db = "nuccore", id = "MW165880.1", rettype="fasta_cds_na")
# Get bioclim vars from climate data
library(raster)
library(dismo)
library(parallel)
library(ncdf4)
#setwd("/nfs/ctrisos-data/")
#set years of data
start.year=1981
end.year=1995
#get land grid
#Guessing you don't need this because only have ERA land?
#landgrid<-raster('ClimateModelScript/landMaskQD.tif')
# set the number of cores
detectCores()
mc.cores=8
# get climate data from netcdf into rasterbricks
tasmax<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
tasmin<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
precip<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
tasmax
# Get bioclim vars from climate data
library(raster)
library(dismo)
library(parallel)
library(ncdf4)
#setwd("/nfs/ctrisos-data/")
#set years of data
start.year=1981
end.year=1995
#get land grid
#Guessing you don't need this because only have ERA land?
#landgrid<-raster('ClimateModelScript/landMaskQD.tif')
# set the number of cores
detectCores()
mc.cores=8
# get climate data from netcdf into rasterbricks
tasmax<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
tasmin<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
precip<-brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
blank <- matrix(0,360*2,720*2) # proper resolution
blank <- raster(blank)
extent(blank) <- c(-180, 180, -90, 90)
projection(blank) <- CRS("+proj=longlat +datum=WGS84")
precip <- resample(precip, blank)
precip
library(raster)
library(ncdf4)
tas <- brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
pre <- brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386711.0461376-16515-23-dfb714e2-04ed-42b3-b4c5-805def808674.nc")
blank <- matrix(0,360*2,720*2) # proper resolution
blank <- raster(blank)
extent(blank) <- c(-180, 180, -90, 90)
projection(blank) <- CRS("+proj=longlat +datum=WGS84")
pre <- resample(pre, blank)
tas <- resample(tas, blank)
writeRaster("C:/Users/cjcar/Dropbox/ERA5 Iceberg")
pre
tas
tas <- tas[1:360]
tas
tas
tas <- brick("C:/Users/cjcar/Downloads/adaptor.mars.internal-1605386567.6335182-13770-31-377b4dc6-4585-4c7e-88fb-57b7de0a8859.nc")
tas <- resample(tas, blank)
tas[[1:360]]
tas <- tas[[1:360]]
writeRaster(pre, "C:/Users/cjcar/Dropbox/ERA5 Iceberg/pre.nc")
writeRaster(tas, "C:/Users/cjcar/Dropbox/ERA5 Iceberg/tas.nc")
library(tidyverse)
gen <- read_delim(file.choose())
gen <- read_delim(file.choose())
gen <- read_delim(file.choose(), delim = '\t')
View(gen)
library(classInt)
library(tidyverse)
library(raster)
library(rgdal)
library(dismo)
library(XML)
library(maps)
library(sp)
library(velox)
setwd("~/Github/hantaro")
set.seed(12345)
# Read in the data
pred <- read_csv("./data/clean files/hantaro predictions.csv")
# 1. Threshold the results
library(PresenceAbsence)
?optimal.thresholds
ts.p <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
threshold = 10001,
opt.methods = c(2,4,5,10),
req.sens = 0.95,
na.rm = TRUE)
cut.p <- function(x) {table(pred$pred_pcr[pred$PCR==0] > x)}
ts.p
sapply(cut.p, ts.p[,2])
ts.p[2]
sapply(cut.p, ts.p[2])
ts.p[2]
sapply(ts.p[2], cut.p)
cut.p <- function(x) {sum(pred$pred_pcr[pred$PCR==0] > x)}
sapply(ts.p[2], cut.p)
sapply(as.vector(ts.p[2]), cut.p)
as.vector(ts.p[2])
unlist(ts.p)
unlist(ts.p[2])
sapply(unlist(ts.p[2]), cut.p)
ts.c <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
threshold = 10001,
opt.methods = c(2,4,5,10),
req.sens = 0.95,
na.rm = TRUE)
cut.c <- function(x) {sum(pred$pred_comp[pred$competence==0] > x)}
sapply(unlist(ts.c[2]), cut.c)
ts.p <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
threshold = 10001,
opt.methods = c(2,4,5,10),
req.sens = c(0.90,0.95),
na.rm = TRUE)
cut.p <- function(x) {sum(pred$pred_pcr[pred$PCR==0] > x)}
sapply(unlist(ts.p[2]), cut.p)
ts.p <- optimal.thresholds(data.frame(pred[,c('treename','PCR','pred_pcr')]),
threshold = 10001,
opt.methods = c(2,4,5,10),
req.sens = 0.90,
na.rm = TRUE)
cut.p <- function(x) {sum(pred$pred_pcr[pred$PCR==0] > x)}
sapply(unlist(ts.p[2]), cut.p)
ts.c <- optimal.thresholds(data.frame(pred[,c('treename','competence','pred_comp')]),
threshold = 10001,
opt.methods = c(2,4,5,10),
req.sens = 0.90,
na.rm = TRUE)
cut.c <- function(x) {sum(pred$pred_comp[pred$competence==0] > x)}
sapply(unlist(ts.c[2]), cut.c)
